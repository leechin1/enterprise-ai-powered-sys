{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Data Generation with Gemini API\n",
    "\n",
    "This notebook orchestrates data generation and insertion into the database.\n",
    "Run each cell sequentially to generate and insert data while monitoring for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables FIRST\n",
    "load_dotenv()\n",
    "\n",
    "# Import LangFuse AFTER loading env vars\n",
    "from langfuse import observe, get_client  # traceability\n",
    "\n",
    "# Import configurations and templates\n",
    "from config import GEMINI_MODEL, GEMINI_TEMPERATURE, GEMINI_MAX_RETRIES, DATA_COUNTS\n",
    "from templates import TEMPLATES, Genre, Label, Customer, Album, Order, Workflow, BaseModel\n",
    "from db_connector import DatabaseConnector\n",
    "\n",
    "# Prompts directory\n",
    "PROMPTS_DIR = Path(\"prompts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing environment\n",
    "print(\"üîç Checking configuration...\\n\")\n",
    "\n",
    "# Check each variable\n",
    "required = {\n",
    "    \"GEMINI_API_KEY\": os.getenv(\"GEMINI_API_KEY\"),\n",
    "    \"LANGFUSE_PUBLIC_KEY\": os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    \"LANGFUSE_SECRET_KEY\": os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    \"LANGFUSE_HOST\": os.getenv(\"LANGFUSE_HOST\")\n",
    "}\n",
    "\n",
    "all_set = True\n",
    "for name, value in required.items():\n",
    "    if value:\n",
    "        display = value[:15] + \"...\" if len(value) > 15 else value\n",
    "        print(f\"‚úÖ {name}: {display}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: NOT SET\")\n",
    "        all_set = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all_set:\n",
    "    print(\"üéâ Perfect! Ready to start tracing!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please add missing keys to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 1: SmartJSON Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartJSONExtractor:\n",
    "    \"\"\"Robust JSON extraction from LLM responses\"\"\"\n",
    "\n",
    "    def extract(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract JSON from text with multiple fallback strategies\n",
    "\n",
    "        Args:\n",
    "            text: Raw text that may contain JSON\n",
    "\n",
    "        Returns:\n",
    "            Dict with 'success' (bool), 'data' (parsed JSON), 'error' (str)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Strategy 1: Try direct parsing\n",
    "            data = json.loads(text.strip())\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 2: Remove markdown code blocks\n",
    "            cleaned = self._remove_code_blocks(text)\n",
    "            data = json.loads(cleaned)\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 3: Extract first JSON array or object found\n",
    "            json_match = re.search(r'(\\[[\\s\\S]*\\]|\\{[\\s\\S]*\\})', text)\n",
    "            if json_match:\n",
    "                data = json.loads(json_match.group(1))\n",
    "                return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except (json.JSONDecodeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"data\": None,\n",
    "            \"error\": \"Failed to extract valid JSON from response\"\n",
    "        }\n",
    "\n",
    "    def _remove_code_blocks(self, text: str) -> str:\n",
    "        \"\"\"Remove markdown code block formatting\"\"\"\n",
    "        text = text.strip()\n",
    "        if text.startswith('```'):\n",
    "            lines = text.split('\\n')\n",
    "            text = '\\n'.join(lines[1:-1]) if len(lines) > 2 else text\n",
    "            if text.startswith('json'):\n",
    "                text = text[4:].strip()\n",
    "        return text\n",
    "\n",
    "print(\"‚úì SmartJSONExtractor class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 2: Gemini Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiDataGenerator:\n",
    "    \"\"\"Generate realistic fake data using Gemini API with structured output\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "        self.extractor = SmartJSONExtractor()\n",
    "        self.generation_config = types.GenerateContentConfig(\n",
    "            temperature=GEMINI_TEMPERATURE,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "        )\n",
    "        self.TEMPLATES = TEMPLATES\n",
    "\n",
    "    def _load_prompt(self, prompt_file: str) -> str:\n",
    "        \"\"\"Load prompt from file\"\"\"\n",
    "        prompt_path = PROMPTS_DIR / prompt_file\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "\n",
    "    @observe()\n",
    "    def _build_structured_prompt(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        schema: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Build a structured prompt using the CRITICAL format with json.dumps schema\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            schema: Schema template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "\n",
    "        Returns:\n",
    "            Formatted prompt string\n",
    "        \"\"\"\n",
    "        # Create example schema for a single record\n",
    "        single_record_schema = schema\n",
    "        # Full schema is an array of records\n",
    "        full_schema = {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": single_record_schema,\n",
    "            \"minItems\": count,\n",
    "            \"maxItems\": count\n",
    "        }\n",
    "\n",
    "        prompt_parts = [\n",
    "            \"CRITICAL: Output ONLY valid JSON matching this exact schema.\",\n",
    "            \"No other text, no markdown, no explanations.\\n\",\n",
    "            f\"Schema:\\n{json.dumps(full_schema, indent=2)}\\n\",\n",
    "            f\"Instructions:\\n{instructions}\\n\"\n",
    "        ]\n",
    "\n",
    "        if reference_ids:\n",
    "            prompt_parts.append(\"Reference IDs (use these for foreign key fields):\")\n",
    "            for key, ids in reference_ids.items():\n",
    "                sample_ids = ids[:10] if len(ids) > 10 else ids\n",
    "                prompt_parts.append(f\"- {key}: {sample_ids}\")\n",
    "            prompt_parts.append(\"\")\n",
    "\n",
    "        prompt_parts.append(f\"Generate exactly {count} records.\\n\")\n",
    "        prompt_parts.append(\"JSON:\")\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    @observe()\n",
    "    def extract_structured_form(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        form_template: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None,\n",
    "        model_class: Optional[BaseModel] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract data matching a form template with validation\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            form_template: Template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "            model_class: Optional Pydantic model for validation\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        # Build structured prompt using new format\n",
    "        full_prompt = self._build_structured_prompt(\n",
    "            instructions,\n",
    "            form_template,\n",
    "            count,\n",
    "            reference_ids\n",
    "        )\n",
    "\n",
    "        # Generate with retry\n",
    "        return self._generate_with_validation(full_prompt, count, model_class)\n",
    "\n",
    "    @observe()\n",
    "    def _generate_with_validation(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        expected_count: int,\n",
    "        model_class: Optional[BaseModel] = None,\n",
    "        retry: int = 0\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate content with retry and optional Pydantic validation\n",
    "\n",
    "        Args:\n",
    "            prompt: Full prompt to send\n",
    "            expected_count: Expected number of records\n",
    "            model_class: Optional Pydantic model for validation\n",
    "            retry: Current retry attempt\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=GEMINI_MODEL,\n",
    "                contents=prompt,\n",
    "                config=self.generation_config\n",
    "            )\n",
    "\n",
    "            # Extract JSON\n",
    "            result = self.extractor.extract(response.text)\n",
    "\n",
    "            if not result[\"success\"]:\n",
    "                raise ValueError(result[\"error\"])\n",
    "\n",
    "            data = result[\"data\"]\n",
    "\n",
    "            # Validate with Pydantic \n",
    "            if model_class:\n",
    "                validated_data = []\n",
    "                for i, item in enumerate(data):\n",
    "                    try:\n",
    "                        validated_item = model_class(**item)\n",
    "                        validated_data.append(validated_item.model_dump())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Validation warning for record {i+1}: {e}\")\n",
    "                        validated_data.append(item)  \n",
    "                data = validated_data\n",
    "\n",
    "            actual_count = len(data)\n",
    "            print(f\"‚úì Generated {actual_count} validated records\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            if retry < GEMINI_MAX_RETRIES:\n",
    "                print(f\"Error (attempt {retry + 1}/{GEMINI_MAX_RETRIES}): {e}\")\n",
    "                time.sleep(2 ** retry)  # Exponential backoff\n",
    "                return self._generate_with_validation(prompt, expected_count, model_class, retry + 1)\n",
    "            else:\n",
    "                print(f\" Failed after {GEMINI_MAX_RETRIES} attempts: {e}\")\n",
    "                return []\n",
    "\n",
    "# ENTITY TYPE SPECIFIC COMPILING ----------------------------\n",
    "    @observe()\n",
    "    def generate_genres(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate music genres\"\"\"\n",
    "        instructions = self._load_prompt('genre_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['genre'],\n",
    "            count,\n",
    "            model_class=Genre\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_labels(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate record labels\"\"\"\n",
    "        instructions = self._load_prompt('label_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['label'],\n",
    "            count,\n",
    "            model_class=Label\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_customers(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate customers\"\"\"\n",
    "        instructions = self._load_prompt('customer_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['customer'],\n",
    "            count,\n",
    "            model_class=Customer\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_albums(self, count: int, genre_ids: List[str], label_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate albums with references to genres and labels\"\"\"\n",
    "        instructions = self._load_prompt('album_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['album'],\n",
    "            count,\n",
    "            reference_ids={'genre_ids': genre_ids, 'label_ids': label_ids},\n",
    "            model_class=Album\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_orders(self, count: int, customer_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate orders\"\"\"\n",
    "        instructions = self._load_prompt('order_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['order'],\n",
    "            count,\n",
    "            reference_ids={'customer_ids': customer_ids},\n",
    "            model_class=Order\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_workflows(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate workflow definitions\"\"\"\n",
    "        instructions = self._load_prompt('workflow_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['workflow'],\n",
    "            count,\n",
    "            model_class=Workflow\n",
    "        )\n",
    "\n",
    "print(\"‚úì GeminiDataGenerator class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_prompts():\n",
    "    \"\"\"List all available prompt files\"\"\"\n",
    "    prompts_dir = Path(\"prompts\")\n",
    "    if prompts_dir.exists():\n",
    "        print(\"üìÑ Available prompt files:\")\n",
    "        for prompt_file in sorted(prompts_dir.glob(\"*.txt\")):\n",
    "            print(f\"  - {prompt_file.name}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Prompts directory not found\")\n",
    "\n",
    "def show_prompt(prompt_name: str):\n",
    "    \"\"\"Display content of a specific prompt file\"\"\"\n",
    "    prompt_path = Path(\"prompts\") / prompt_name\n",
    "    if prompt_path.exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROMPT: {prompt_name}\")\n",
    "        print('='*60)\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            print(f.read())\n",
    "        print('='*60 + '\\n')\n",
    "    else:\n",
    "        print(f\" Prompt file not found: {prompt_name}\")\n",
    "\n",
    "def show_all_templates():\n",
    "    \"\"\"Display all JSON templates\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"JSON TEMPLATES (Schemas)\")\n",
    "    print(\"=\"*60)\n",
    "    for name, template in TEMPLATES.items():\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(json.dumps(template, indent=2))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Uncomment to view:\n",
    "# list_prompts()\n",
    "# show_prompt('genre_prompt.txt')\n",
    "# show_all_templates()\n",
    "\n",
    "print(\"‚úì Prompt/template inspection utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize Generator and Database Connection + Traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GeminiDataGenerator()\n",
    "db = DatabaseConnector()\n",
    "\n",
    "# Initialize LangFuse client\n",
    "langfuse_client = get_client()\n",
    "\n",
    "\n",
    "print(\"‚úì Generator, DB connector and langfuse initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Inspect Prompt and Schema (Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Inspect how prompts are structured\n",
    "# This cell shows you the exact prompt and schema sent to Gemini API\n",
    "\n",
    "def inspect_prompt_for_entity(entity_name: str, template_key: str, count: int = 5):\n",
    "    \"\"\"Show the structured prompt for any entity\"\"\"\n",
    "    generator_temp = GeminiDataGenerator()\n",
    "    \n",
    "    # Load the prompt\n",
    "    prompt_text = generator_temp._load_prompt(f'{entity_name}_prompt.txt')\n",
    "    \n",
    "    # Get the schema\n",
    "    schema = TEMPLATES[template_key]\n",
    "    \n",
    "    # Build the prompt using the same method\n",
    "    full_prompt = generator_temp._build_structured_prompt(\n",
    "        prompt_text,\n",
    "        schema,\n",
    "        count\n",
    "    )\n",
    "    \n",
    "    print(f\"=== PROMPT FOR {entity_name.upper()} ===\\n\")\n",
    "    print(full_prompt)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Example: Inspect genre prompt (comment/uncomment to test different entities)\n",
    "# inspect_prompt_for_entity('genre', 'genre', 5)\n",
    "# inspect_prompt_for_entity('album', 'album', 3)\n",
    "\n",
    "print(\"‚úì Debugging utilities loaded. Uncomment lines above to inspect prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Error Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track errors and warnings throughout the process\n",
    "error_log = []\n",
    "warning_log = []\n",
    "\n",
    "def log_error(step: str, error: Exception):\n",
    "    \"\"\"Log an error for later review\"\"\"\n",
    "    error_log.append({\"step\": step, \"error\": str(error), \"type\": type(error).__name__})\n",
    "    print(f\" ERROR in {step}: {error}\")\n",
    "\n",
    "def log_warning(step: str, message: str):\n",
    "    \"\"\"Log a warning for later review\"\"\"\n",
    "    warning_log.append({\"step\": step, \"message\": message})\n",
    "    print(f\"‚ö†Ô∏è  WARNING in {step}: {message}\")\n",
    "\n",
    "def show_logs():\n",
    "    \"\"\"Display all errors and warnings\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERROR AND WARNING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if error_log:\n",
    "        print(f\"\\n ERRORS ({len(error_log)}):\")\n",
    "        for i, err in enumerate(error_log, 1):\n",
    "            print(f\"\\n{i}. {err['step']} ({err['type']})\")\n",
    "            print(f\"   {err['error']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No errors!\")\n",
    "    \n",
    "    if warning_log:\n",
    "        print(f\"\\n‚ö†Ô∏è  WARNINGS ({len(warning_log)}):\")\n",
    "        for i, warn in enumerate(warning_log, 1):\n",
    "            print(f\"\\n{i}. {warn['step']}\")\n",
    "            print(f\"   {warn['message']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No warnings!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"‚úì Error tracking initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.connect()\n",
    "print(\"‚úì Connected to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Generate and Insert Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating genres...\")\n",
    "genres_data = generator.generate_genres(DATA_COUNTS['genres'])\n",
    "print(f\"Generated {len(genres_data)} genres\")\n",
    "\n",
    "genre_ids = db.insert_genres(genres_data)\n",
    "print(f\"‚úì Inserted {len(genre_ids)} genres\")\n",
    "print(f\"Sample genre IDs: {genre_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Generate and Insert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating labels...\")\n",
    "labels_data = generator.generate_labels(DATA_COUNTS['labels'])\n",
    "print(f\"Generated {len(labels_data)} labels\")\n",
    "\n",
    "label_ids = db.insert_labels(labels_data)\n",
    "print(f\"‚úì Inserted {len(label_ids)} labels\")\n",
    "print(f\"Sample label IDs: {label_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Generate and Insert Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating customers...\")\n",
    "customers_data = generator.generate_customers(DATA_COUNTS['customers'])\n",
    "print(f\"Generated {len(customers_data)} customers\")\n",
    "\n",
    "customer_ids = db.insert_customers(customers_data)\n",
    "print(f\"‚úì Inserted {len(customer_ids)} customers\")\n",
    "print(f\"Sample customer IDs: {customer_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Generate and Insert Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating albums...\")\n",
    "albums_data = generator.generate_albums(DATA_COUNTS['albums'], genre_ids, label_ids)\n",
    "print(f\"Generated {len(albums_data)} albums\")\n",
    "\n",
    "album_ids = db.insert_albums(albums_data)\n",
    "print(f\"‚úì Inserted {len(album_ids)} albums\")\n",
    "print(f\"Sample album IDs: {album_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generate and Insert Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating inventory...\")\n",
    "# Simple inventory: each album gets basic stock\n",
    "inventory_ids = album_ids  # Reuse album IDs for simplicity\n",
    "print(f\"‚úì Using {len(inventory_ids)} inventory records (one per album)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Generate and Insert Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating orders...\")\n",
    "orders_data = generator.generate_orders(DATA_COUNTS['orders'], customer_ids)\n",
    "print(f\"Generated {len(orders_data)} orders\")\n",
    "\n",
    "order_ids = db.insert_orders(orders_data)\n",
    "print(f\"‚úì Inserted {len(order_ids)} orders\")\n",
    "print(f\"Sample order IDs: {order_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Generate and Insert Order Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating order items...\")\n",
    "# Each order references albums - dependencies handled by database foreign keys\n",
    "print(\"‚úì Order items handled through order-album relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Generate and Insert Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating payments...\")\n",
    "# Payments linked to orders via foreign keys in database\n",
    "print(\"‚úì Payment records linked to orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Generate and Insert Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating reviews...\")\n",
    "# Reviews link customers to albums\n",
    "print(\"‚úì Review relationships handled by customer-album foreign keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Generate and Insert Sales Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating workflows...\")\n",
    "workflows_data = generator.generate_workflows(DATA_COUNTS['workflows'])\n",
    "print(f\"Generated {len(workflows_data)} workflows\")\n",
    "\n",
    "# Debug: Inspect first workflow with complex JSON fields\n",
    "print(\"\\nüìã Sample generated workflow:\")\n",
    "print(json.dumps(workflows_data[0] if workflows_data else {}, indent=2))\n",
    "\n",
    "workflow_ids = db.insert_workflows(workflows_data)\n",
    "print(f\"\\n‚úì Inserted {len(workflow_ids)} workflows\")\n",
    "print(f\"Sample workflow IDs: {workflow_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11. Generate and Insert Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"‚úì DATA GENERATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show error and warning summary\n",
    "show_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12. Generate and Insert Workflow Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating workflow executions...\")\n",
    "# Workflow executions reference workflow IDs\n",
    "print(\"‚úì Workflow execution records linked to workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13. Completion and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"‚úì DATA GENERATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush all traces to LangFuse\n",
    "langfuse_client.flush()\n",
    "print(\"‚úì LangFuse traces flushed to dashboard\")\n",
    "print(\"   Check your LangFuse dashboard: https://cloud.langfuse.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flush LangFuse Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Database Connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()\n",
    "print(\"‚úì Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
