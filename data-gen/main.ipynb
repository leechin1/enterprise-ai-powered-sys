{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Data Generation with Gemini API\n",
    "\n",
    "This notebook orchestrates data generation and insertion into the database.\n",
    "\n",
    "Notes:\n",
    "- As development happened: some LLM data generators were depreceated over random methods due to exhaustive computation and unnecessary, since it would not change much for our purpose\n",
    "- Order and order items logic: order is a high level abstraction of each transaction detailed in order items. Given that we are using random methods, it is hard to predict how order items might come across so we are instead generating these first (with the order id) and then overwriting the total. In a real case data flow scenario, this would not make sense but for our use case, is the best possible emplyment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import logging\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Load environment variables FIRST\n",
    "load_dotenv()\n",
    "\n",
    "# Silence OpenTelemetry (Langfuse) errors\n",
    "logging.getLogger(\"opentelemetry.sdk._shared_internal\").setLevel(logging.CRITICAL)\n",
    "\n",
    "from langfuse import observe, get_client  # traceability\n",
    "\n",
    "# Import configurations and templates\n",
    "from config import *\n",
    "from db_connector import DatabaseConnector\n",
    "\n",
    "# Prompts directory\n",
    "PROMPTS_DIR = Path(\"prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking configuration...\n",
      "\n",
      "‚úÖ GEMINI_API_KEY: AIzaSyBmeV92JOQ...\n",
      "‚úÖ LANGFUSE_PUBLIC_KEY: pk-lf-f2596628-...\n",
      "‚úÖ LANGFUSE_SECRET_KEY: sk-lf-9793468d-...\n",
      "‚úÖ LANGFUSE_HOST: https://cloud.l...\n",
      "\n",
      "==================================================\n",
      "üéâ Perfect! Ready to start tracing!\n"
     ]
    }
   ],
   "source": [
    "# Testing environment\n",
    "print(\"üîç Checking configuration...\\n\")\n",
    "\n",
    "# Check each variable\n",
    "required = {\n",
    "    \"GEMINI_API_KEY\": os.getenv(\"GEMINI_API_KEY\"),\n",
    "    \"LANGFUSE_PUBLIC_KEY\": os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    \"LANGFUSE_SECRET_KEY\": os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    \"LANGFUSE_HOST\": os.getenv(\"LANGFUSE_HOST\")\n",
    "}\n",
    "\n",
    "all_set = True\n",
    "for name, value in required.items():\n",
    "    if value:\n",
    "        display = value[:15] + \"...\" if len(value) > 15 else value\n",
    "        print(f\"‚úÖ {name}: {display}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: NOT SET\")\n",
    "        all_set = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all_set:\n",
    "    print(\"üéâ Perfect! Ready to start tracing!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please add missing keys to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 1: SmartJSON Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì SmartJSONExtractor class loaded\n"
     ]
    }
   ],
   "source": [
    "class SmartJSONExtractor:\n",
    "    \"\"\"Robust JSON extraction from LLM responses\"\"\"\n",
    "\n",
    "    def extract(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract JSON from text with multiple fallback strategies\n",
    "\n",
    "        Args:\n",
    "            text: Raw text that may contain JSON\n",
    "\n",
    "        Returns:\n",
    "            Dict with 'success' (bool), 'data' (parsed JSON), 'error' (str)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Strategy 1: Try direct parsing\n",
    "            data = json.loads(text.strip())\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 2: Remove markdown code blocks\n",
    "            cleaned = self._remove_code_blocks(text)\n",
    "            data = json.loads(cleaned)\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 3: Extract first JSON array or object found\n",
    "            json_match = re.search(r'(\\[[\\s\\S]*\\]|\\{[\\s\\S]*\\})', text)\n",
    "            if json_match:\n",
    "                data = json.loads(json_match.group(1))\n",
    "                return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except (json.JSONDecodeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"data\": None,\n",
    "            \"error\": \"Failed to extract valid JSON from response\"\n",
    "        }\n",
    "\n",
    "    def _remove_code_blocks(self, text: str) -> str:\n",
    "        \"\"\"Remove markdown code block formatting\"\"\"\n",
    "        text = text.strip()\n",
    "        if text.startswith('```'):\n",
    "            lines = text.split('\\n')\n",
    "            text = '\\n'.join(lines[1:-1]) if len(lines) > 2 else text\n",
    "            if text.startswith('json'):\n",
    "                text = text[4:].strip()\n",
    "        return text\n",
    "\n",
    "print(\"‚úì SmartJSONExtractor class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 2: Gemini Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì GeminiDataGenerator class loaded\n"
     ]
    }
   ],
   "source": [
    "class GeminiDataGenerator:\n",
    "    \"\"\"Generate realistic fake data using Gemini API with structured output\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "        self.extractor = SmartJSONExtractor()\n",
    "        self.generation_config = types.GenerateContentConfig(\n",
    "            system_instruction=[\n",
    "            \"You're a synthetic data generator for an enterprise jazz vinyl record application, whose clients have very exquisite taste.\",\n",
    "            \"Your clients value authenticity, hence try to choose real-world examples when available first.\",\n",
    "        ],\n",
    "            temperature=GEMINI_TEMPERATURE,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "        )\n",
    "        self.TEMPLATES = TEMPLATES\n",
    "\n",
    "    def _load_prompt(self, prompt_file: str) -> str:\n",
    "        \"\"\"Load prompt from file\"\"\"\n",
    "        prompt_path = PROMPTS_DIR / prompt_file\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "\n",
    "    @observe()\n",
    "    def _build_structured_prompt(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        schema: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Build a structured prompt using the CRITICAL format with json.dumps schema\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            schema: Schema template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "\n",
    "        Returns:\n",
    "            Formatted prompt string\n",
    "        \"\"\"\n",
    "        # Create example schema for a single record\n",
    "        single_record_schema = schema\n",
    "        # Full schema is an array of records\n",
    "        full_schema = {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": single_record_schema,\n",
    "            \"minItems\": count,\n",
    "            \"maxItems\": count\n",
    "        }\n",
    "\n",
    "        prompt_parts = [\n",
    "            \"CRITICAL: Output ONLY valid JSON matching this exact schema.\",\n",
    "            \"No other text, no markdown, no explanations.\\n\",\n",
    "            f\"Schema:\\n{json.dumps(full_schema, indent=2)}\\n\",\n",
    "            f\"Instructions:\\n{instructions}\\n\"\n",
    "        ]\n",
    "\n",
    "        if reference_ids:\n",
    "            prompt_parts.append(\"Reference IDs (use these for foreign key fields):\")\n",
    "            for key, ids in reference_ids.items():\n",
    "                sample_ids = ids[:10] if len(ids) > 10 else ids\n",
    "                prompt_parts.append(f\"- {key}: {sample_ids}\")\n",
    "            prompt_parts.append(\"\")\n",
    "\n",
    "        prompt_parts.append(f\"Generate exactly {count} records.\\n\")\n",
    "        prompt_parts.append(\"JSON:\")\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    @observe()\n",
    "    def extract_structured_form(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        form_template: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None,\n",
    "        model_class: Optional[BaseModel] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract data matching a form template with validation\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            form_template: Template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "            model_class: Optional Pydantic model for validation\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        # Build structured prompt using new format\n",
    "        full_prompt = self._build_structured_prompt(\n",
    "            instructions,\n",
    "            form_template,\n",
    "            count,\n",
    "            reference_ids\n",
    "        )\n",
    "\n",
    "        # Generate with retry\n",
    "        return self._generate_with_validation(full_prompt, count, model_class)\n",
    "\n",
    "    @observe()\n",
    "    def _generate_with_validation(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        expected_count: int,\n",
    "        model_class: Optional[BaseModel] = None,\n",
    "        retry: int = 0\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate content with retry and optional Pydantic validation\n",
    "\n",
    "        Args:\n",
    "            prompt: Full prompt to send\n",
    "            expected_count: Expected number of records\n",
    "            model_class: Optional Pydantic model for validation\n",
    "            retry: Current retry attempt\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=GEMINI_MODEL,\n",
    "                contents=prompt,\n",
    "                config=self.generation_config\n",
    "            )\n",
    "\n",
    "            # Extract JSON\n",
    "            result = self.extractor.extract(response.text)\n",
    "\n",
    "            if not result[\"success\"]:\n",
    "                raise ValueError(result[\"error\"])\n",
    "\n",
    "            data = result[\"data\"]\n",
    "\n",
    "            # Validate with Pydantic \n",
    "            if model_class:\n",
    "                validated_data = []\n",
    "                for i, item in enumerate(data):\n",
    "                    try:\n",
    "                        validated_item = model_class(**item)\n",
    "                        validated_data.append(validated_item.model_dump())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Validation warning for record {i+1}: {e}\")\n",
    "                        validated_data.append(item)  \n",
    "                data = validated_data\n",
    "\n",
    "            actual_count = len(data)\n",
    "            print(f\"‚úì Generated {actual_count} validated records\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            if retry < GEMINI_MAX_RETRIES:\n",
    "                print(f\"Error (attempt {retry + 1}/{GEMINI_MAX_RETRIES}): {e}\")\n",
    "                time.sleep(2 ** retry)  # Exponential backoff\n",
    "                return self._generate_with_validation(prompt, expected_count, model_class, retry + 1)\n",
    "            else:\n",
    "                print(f\" Failed after {GEMINI_MAX_RETRIES} attempts: {e}\")\n",
    "                return []\n",
    "\n",
    "# ENTITY TYPE SPECIFIC COMPILING ----------------------------\n",
    "    @observe()\n",
    "    def generate_genres(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate music genres\"\"\"\n",
    "        instructions = self._load_prompt('genre_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['genre'],\n",
    "            count,\n",
    "            model_class=Genre\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_labels(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate record labels\"\"\"\n",
    "        instructions = self._load_prompt('label_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['label'],\n",
    "            count,\n",
    "            model_class=Label\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_customers(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate customers\"\"\"\n",
    "        instructions = self._load_prompt('customer_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['customer'],\n",
    "            count,\n",
    "            model_class=Customer\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_albums(self, count: int, genre_ids: List[str], label_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate albums with references to genres and labels\"\"\"\n",
    "        instructions = self._load_prompt('album_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['album'],\n",
    "            count,\n",
    "            reference_ids={'genre_ids': genre_ids, 'label_ids': label_ids},\n",
    "            model_class=Album\n",
    "        )\n",
    "    # UNUSED - depreceated over manual input\n",
    "    @observe()\n",
    "    def generate_orders(self, count: int, customer_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate orders\"\"\"\n",
    "        instructions = self._load_prompt('order_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['order'],\n",
    "            count,\n",
    "            reference_ids={'customer_ids': customer_ids},\n",
    "            model_class=Order\n",
    "        )\n",
    "    # UNUSED- not needed\n",
    "    @observe()\n",
    "    def generate_workflows(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate workflow definitions\"\"\"\n",
    "        instructions = self._load_prompt('workflow_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['workflow'],\n",
    "            count,\n",
    "            model_class=Workflow\n",
    "        )\n",
    "    # UNUSED over manual random generation\n",
    "    @observe()\n",
    "    def generate_order_items(self, order_ids: List[str], album_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate order items for all orders\"\"\"\n",
    "        instructions = self._load_prompt('order_item_prompt.txt')\n",
    "        \n",
    "        # Generate 1-5 items per order\n",
    "        total_items = sum(random.randint(1, 5) for _ in order_ids)\n",
    "        \n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['order_item'],\n",
    "            total_items,\n",
    "            reference_ids={'order_ids': order_ids, 'album_ids': album_ids},\n",
    "            model_class=OrderItem\n",
    "        )\n",
    "    # UNUSED over manual random generation\n",
    "    @observe()\n",
    "    def generate_payments(self, count: int, order_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate payment records\"\"\"\n",
    "        instructions = self._load_prompt('payment_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['payment'],\n",
    "            count,\n",
    "            reference_ids={'order_ids': order_ids},\n",
    "            model_class=Payment\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_reviews(self, count: int, customer_ids: List[str], album_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate customer reviews\"\"\"\n",
    "        instructions = self._load_prompt('review_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['review'],\n",
    "            count,\n",
    "            reference_ids={'customer_ids': customer_ids, 'album_ids': album_ids},\n",
    "            model_class=Review\n",
    "        )\n",
    "\n",
    "print(\"‚úì GeminiDataGenerator class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Available prompt files:\n",
      "  - album_prompt.txt\n",
      "  - customer_prompt.txt\n",
      "  - genre_prompt.txt\n",
      "  - label_prompt.txt\n",
      "  - order_item_prompt.txt\n",
      "  - order_prompt.txt\n",
      "  - payment_prompt.txt\n",
      "  - review_prompt.txt\n",
      "  - workflow_prompt.txt\n",
      "\n",
      "============================================================\n",
      "JSON TEMPLATES (Schemas)\n",
      "============================================================\n",
      "\n",
      "GENRE:\n",
      "{\n",
      "  \"name\": null\n",
      "}\n",
      "\n",
      "LABEL:\n",
      "{\n",
      "  \"name\": null\n",
      "}\n",
      "\n",
      "CUSTOMER:\n",
      "{\n",
      "  \"email\": null,\n",
      "  \"first_name\": null,\n",
      "  \"last_name\": null,\n",
      "  \"phone\": null\n",
      "}\n",
      "\n",
      "ALBUM:\n",
      "{\n",
      "  \"title\": null,\n",
      "  \"artist\": null,\n",
      "  \"genre_id\": null,\n",
      "  \"label_id\": null,\n",
      "  \"price\": null\n",
      "}\n",
      "\n",
      "ORDER:\n",
      "{\n",
      "  \"order_number\": null,\n",
      "  \"customer_id\": null,\n",
      "  \"shipping_address\": null,\n",
      "  \"order_date\": null\n",
      "}\n",
      "\n",
      "WORKFLOW:\n",
      "{\n",
      "  \"name\": null,\n",
      "  \"description\": null,\n",
      "  \"trigger_type\": null,\n",
      "  \"trigger_config\": {},\n",
      "  \"workflow_definition\": {},\n",
      "  \"enabled\": null\n",
      "}\n",
      "\n",
      "ORDER_ITEM:\n",
      "{\n",
      "  \"order_id\": null,\n",
      "  \"album_id\": null,\n",
      "  \"quantity\": null\n",
      "}\n",
      "\n",
      "PAYMENT:\n",
      "{\n",
      "  \"order_id\": null,\n",
      "  \"amount\": null,\n",
      "  \"payment_method\": null,\n",
      "  \"status\": null,\n",
      "  \"transaction_id\": null\n",
      "}\n",
      "\n",
      "REVIEW:\n",
      "{\n",
      "  \"customer_id\": null,\n",
      "  \"album_id\": null,\n",
      "  \"rating\": null,\n",
      "  \"review_text\": null\n",
      "}\n",
      "\n",
      "============================================================\n",
      "‚úì Prompt/template inspection utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def list_prompts():\n",
    "    \"\"\"List all available prompt files\"\"\"\n",
    "    prompts_dir = Path(\"prompts\")\n",
    "    if prompts_dir.exists():\n",
    "        print(\"üìÑ Available prompt files:\")\n",
    "        for prompt_file in sorted(prompts_dir.glob(\"*.txt\")):\n",
    "            print(f\"  - {prompt_file.name}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Prompts directory not found\")\n",
    "\n",
    "def show_prompt(prompt_name: str):\n",
    "    \"\"\"Display content of a specific prompt file\"\"\"\n",
    "    prompt_path = Path(\"prompts\") / prompt_name\n",
    "    if prompt_path.exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROMPT: {prompt_name}\")\n",
    "        print('='*60)\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            print(f.read())\n",
    "        print('='*60 + '\\n')\n",
    "    else:\n",
    "        print(f\" Prompt file not found: {prompt_name}\")\n",
    "\n",
    "def show_all_templates():\n",
    "    \"\"\"Display all JSON templates\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"JSON TEMPLATES (Schemas)\")\n",
    "    print(\"=\"*60)\n",
    "    for name, template in TEMPLATES.items():\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(json.dumps(template, indent=2))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Uncomment to view:\n",
    "list_prompts()\n",
    "show_all_templates()\n",
    "\n",
    "print(\"‚úì Prompt/template inspection utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize Generator and Database Connection + Traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generator, DB connector and langfuse initialized\n"
     ]
    }
   ],
   "source": [
    "generator = GeminiDataGenerator()\n",
    "db = DatabaseConnector()\n",
    "\n",
    "# Initialize LangFuse client\n",
    "langfuse_client = get_client()\n",
    "\n",
    "\n",
    "print(\"‚úì Generator, DB connector and langfuse initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Inspect Prompt and Schema (Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Debugging utilities loaded. Uncomment lines above to inspect prompts.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Inspect how prompts are structured\n",
    "# This cell shows you the exact prompt and schema sent to Gemini API\n",
    "\n",
    "def inspect_prompt_for_entity(entity_name: str, template_key: str, count: int = 5):\n",
    "    \"\"\"Show the structured prompt for any entity\"\"\"\n",
    "    generator_temp = GeminiDataGenerator()\n",
    "    \n",
    "    # Load the prompt\n",
    "    prompt_text = generator_temp._load_prompt(f'{entity_name}_prompt.txt')\n",
    "    \n",
    "    # Get the schema\n",
    "    schema = TEMPLATES[template_key]\n",
    "    \n",
    "    # Build the prompt using the same method\n",
    "    full_prompt = generator_temp._build_structured_prompt(\n",
    "        prompt_text,\n",
    "        schema,\n",
    "        count\n",
    "    )\n",
    "    \n",
    "    print(f\"=== PROMPT FOR {entity_name.upper()} ===\\n\")\n",
    "    print(full_prompt)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Example: Inspect genre prompt (comment/uncomment to test different entities)\n",
    "# inspect_prompt_for_entity('genre', 'genre', 5)\n",
    "# inspect_prompt_for_entity('album', 'album', 3)\n",
    "\n",
    "print(\"‚úì Debugging utilities loaded. Uncomment lines above to inspect prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Error Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Error tracking initialized\n"
     ]
    }
   ],
   "source": [
    "# Track errors and warnings throughout the process\n",
    "error_log = []\n",
    "warning_log = []\n",
    "\n",
    "def log_error(step: str, error: Exception):\n",
    "    \"\"\"Log an error for later review\"\"\"\n",
    "    error_log.append({\"step\": step, \"error\": str(error), \"type\": type(error).__name__})\n",
    "    print(f\" ERROR in {step}: {error}\")\n",
    "\n",
    "def log_warning(step: str, message: str):\n",
    "    \"\"\"Log a warning for later review\"\"\"\n",
    "    warning_log.append({\"step\": step, \"message\": message})\n",
    "    print(f\"‚ö†Ô∏è  WARNING in {step}: {message}\")\n",
    "\n",
    "def show_logs():\n",
    "    \"\"\"Display all errors and warnings\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERROR AND WARNING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if error_log:\n",
    "        print(f\"\\n ERRORS ({len(error_log)}):\")\n",
    "        for i, err in enumerate(error_log, 1):\n",
    "            print(f\"\\n{i}. {err['step']} ({err['type']})\")\n",
    "            print(f\"   {err['error']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No errors!\")\n",
    "    \n",
    "    if warning_log:\n",
    "        print(f\"\\n‚ö†Ô∏è  WARNINGS ({len(warning_log)}):\")\n",
    "        for i, warn in enumerate(warning_log, 1):\n",
    "            print(f\"\\n{i}. {warn['step']}\")\n",
    "            print(f\"   {warn['message']}\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No warnings!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"‚úì Error tracking initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Supabase successfully\n",
      "‚úì Connected to database\n"
     ]
    }
   ],
   "source": [
    "db.connect()\n",
    "print(\"‚úì Connected to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Generate and Insert Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating genres...\n",
      "‚úì Generated 15 validated records\n",
      "Generated 15 genres\n",
      "‚úì Inserted 15 genres\n",
      "Sample genre IDs: ['1f657a18-645d-4206-a431-c45e967bcb1d', '8396d96c-9644-4d83-8cb8-301f9942adae', 'b0718b04-1517-4669-97d3-13b27e79d549', '70a76012-6212-49ff-a125-603de72b02ed', 'ce7b1985-50d6-4f25-9d77-44b8b78b0eaa']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating genres...\")\n",
    "genres_data = generator.generate_genres(DATA_COUNTS['genres'])\n",
    "print(f\"Generated {len(genres_data)} genres\")\n",
    "\n",
    "genre_ids = db.insert_genres(genres_data)\n",
    "print(f\"‚úì Inserted {len(genre_ids)} genres\")\n",
    "print(f\"Sample genre IDs: {genre_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Generate and Insert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels...\n",
      "‚úì Generated 20 validated records\n",
      "Generated 20 labels\n",
      "‚úì Inserted 20 labels\n",
      "Sample label IDs: ['a6debdad-89fb-428d-ba80-e4d1f83b2478', '682957ea-82cf-494b-bca1-3ec2e2938d22', '469b8cb4-5be0-4c27-993f-02f9dc8e1142', '26e329d9-0a0b-4e06-a53d-539cdc6ab27e', '437d32dc-cc1c-4680-81b9-8e556f48b25d']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating labels...\")\n",
    "labels_data = generator.generate_labels(DATA_COUNTS['labels'])\n",
    "print(f\"Generated {len(labels_data)} labels\")\n",
    "\n",
    "label_ids = db.insert_labels(labels_data)\n",
    "print(f\"‚úì Inserted {len(label_ids)} labels\")\n",
    "print(f\"Sample label IDs: {label_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Generate and Insert Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating customers...\n",
      "‚úì Generated 100 validated records\n",
      "Generated 100 customers\n",
      "‚úì Inserted 100 customers\n",
      "Sample customer IDs: ['00c4c355-ed1a-43fb-8ae3-2052e5f95418', 'e9368dcf-6a85-4c63-9967-2af56d151dee', '4babe54a-8b62-49ee-b619-00c093744ad4', '7d75c15f-4bd1-42b3-8bfd-9f0a83479323', 'aeb8127f-d03a-46d7-af63-62c1fef91893']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating customers...\")\n",
    "customers_data = generator.generate_customers(DATA_COUNTS['customers'])\n",
    "print(f\"Generated {len(customers_data)} customers\")\n",
    "\n",
    "customer_ids = db.insert_customers(customers_data)\n",
    "print(f\"‚úì Inserted {len(customer_ids)} customers\")\n",
    "print(f\"Sample customer IDs: {customer_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Generate and Insert Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating albums...\n",
      "‚úì Generated 298 validated records\n",
      "Generated 298 albums\n",
      "‚úì Inserted 298 albums\n",
      "Sample album IDs: ['f91028df-0494-4092-9248-5194651be8bd', '6a5c3554-9eac-43af-8123-ab9e00c76b2a', 'cfc1875b-4247-4680-9c2d-dfa51b4e787a', '1305a889-18be-4ca1-a445-ecf38cd0bc71', '66c16aa0-6f0e-429b-8232-6f05814b982d']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating albums...\")\n",
    "albums_data = generator.generate_albums(DATA_COUNTS['albums'], genre_ids, label_ids)\n",
    "print(f\"Generated {len(albums_data)} albums\")\n",
    "\n",
    "album_ids = db.insert_albums(albums_data)\n",
    "print(f\"‚úì Inserted {len(album_ids)} albums\")\n",
    "print(f\"Sample album IDs: {album_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generate and Insert Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating inventory...\n",
      "Generated 298 inventory records\n",
      "‚úì Inserted 298 inventory records\n",
      "Sample inventory IDs: ['efa93197-ccb7-48ae-8ea3-5b4165fc5eb2', '7d632c03-c47e-499e-a303-758d25c01bb7', '286c49d0-ea8b-4ef2-95ba-dc4177f805d2', '68f96341-a352-4b1e-8088-cede74206c13', 'a09d4f6f-4ca6-4686-9b13-b3dfdab4a78b']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating inventory...\")\n",
    "import random\n",
    "\n",
    "# Create inventory records for each album with random quantity 1-200\n",
    "inventory_data = []\n",
    "for album_id in album_ids:\n",
    "    inventory_data.append({\n",
    "        'album_id': album_id,\n",
    "        'quantity': random.randint(1, 200)\n",
    "    })\n",
    "\n",
    "print(f\"Generated {len(inventory_data)} inventory records\")\n",
    "\n",
    "inventory_ids = db.insert_inventory(inventory_data)\n",
    "print(f\"‚úì Inserted {len(inventory_ids)} inventory records\")\n",
    "print(f\"Sample inventory IDs: {inventory_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Generate and Insert Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating orders...\n",
      "‚úì Generated 150 validated records\n",
      "Generated 150 orders\n",
      "‚úì Inserted 150 orders (totals will be calculated after order items)\n",
      "Sample order IDs: ['e5185ee8-bec2-443e-9201-b728a5da902c', '2ad35ad7-a9f9-4910-9cd5-2d81c5648649', '461f15d8-1a99-45fb-b55b-616c5b6e5cff', '6c58fd7b-d0a8-485b-ba4f-b8bc787dbcaa', 'd6f9d813-0cf3-406a-85f3-15feaae90e21']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating orders...\")\n",
    "orders_data = generator.generate_orders(DATA_COUNTS['orders'], customer_ids)\n",
    "print(f\"Generated {len(orders_data)} orders\")\n",
    "\n",
    "# Insert orders without totals (will be calculated after order items are created)\n",
    "# We need to add total=0.0 temporarily for database constraint (since random generations are not the most predictable)\n",
    "orders_with_temp_total = [dict(order, total=0.0) for order in orders_data]\n",
    "order_ids = db.insert_orders(orders_with_temp_total)\n",
    "print(f\"‚úì Inserted {len(order_ids)} orders (totals will be calculated after order items)\")\n",
    "print(f\"Sample order IDs: {order_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Generate and Insert Order Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating order items...\n",
      "Generated 1601 order items\n",
      "‚úì Inserted 1601 order items\n",
      "Sample order item IDs: ['0e62d431-8886-45e5-8d03-5a62caf396b2', 'a24c8656-ebbd-4cf0-868b-563df09d19e7', '5c4c0927-af32-4187-8fe0-702f0c6d65e2', '7fdc3f24-6022-47bb-866c-ff652b35bd37', '163580eb-2952-4bdb-a33f-360b483fcc7a']\n"
     ]
    }
   ],
   "source": [
    "# Manual random generation\n",
    "\n",
    "print(\"Generating order items...\")\n",
    "\n",
    "order_items_data = []\n",
    "\n",
    "for order_id in order_ids:\n",
    "    # Pick random number of albums for this order (1-20)\n",
    "    num_albums = random.randint(1, 20)\n",
    "    \n",
    "    # Randomly select albums for this order (without replacement within the same order)\n",
    "    selected_albums = random.sample(album_ids, min(num_albums, len(album_ids)))\n",
    "    \n",
    "    # Create order items\n",
    "    for album_id in selected_albums:\n",
    "        order_items_data.append({\n",
    "            'order_id': order_id,\n",
    "            'album_id': album_id,\n",
    "            'quantity': random.randint(1, 3)  # 1-3 quantity per album\n",
    "        })\n",
    "\n",
    "print(f\"Generated {len(order_items_data)} order items\")\n",
    "\n",
    "order_item_ids = db.insert_order_items(order_items_data)\n",
    "print(f\"‚úì Inserted {len(order_item_ids)} order items\")\n",
    "print(f\"Sample order item IDs: {order_item_ids[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7.1. Calculate and Update Order Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating order totals based on order items...\n",
      "Updating 150 orders with calculated totals...\n",
      "‚úì Updated 150 order totals\n",
      "Sample totals: {'e5185ee8-bec2-443e-9201-b728a5da902c': 5137.150000000001, '2ad35ad7-a9f9-4910-9cd5-2d81c5648649': 1340.8200000000002, '461f15d8-1a99-45fb-b55b-616c5b6e5cff': 4259.05}\n"
     ]
    }
   ],
   "source": [
    "# Manual random generation\n",
    "\n",
    "print(\"Calculating order totals based on order items...\")\n",
    "\n",
    "# Fetch album prices from database\n",
    "albums_with_prices = db.get_albums_data()\n",
    "album_price_map = {album['album_id']: float(album['price']) for album in albums_with_prices}\n",
    "\n",
    "# Group order items by order_id and calculate totals\n",
    "from collections import defaultdict\n",
    "order_totals = defaultdict(float)\n",
    "\n",
    "for item in order_items_data:\n",
    "    order_id = item['order_id']\n",
    "    album_id = item['album_id']\n",
    "    quantity = item['quantity']\n",
    "    \n",
    "    # Get price from album\n",
    "    unit_price = album_price_map.get(album_id, 0.0)\n",
    "    item_total = unit_price * quantity\n",
    "    order_totals[order_id] += item_total\n",
    "\n",
    "# Prepare batch update data\n",
    "print(f\"Updating {len(order_totals)} orders with calculated totals...\")\n",
    "update_data = [\n",
    "    {'order_id': order_id, 'total': total}\n",
    "    for order_id, total in order_totals.items()\n",
    "]\n",
    "\n",
    "# Perform batch upsert\n",
    "for update in update_data:\n",
    "    db.client.table('orders').update({'total': update['total']}).eq('order_id', update['order_id']).execute()\n",
    "\n",
    "print(f\"‚úì Updated {len(order_totals)} order totals\")\n",
    "print(f\"Sample totals: {dict(list(order_totals.items())[:3])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Generate and Insert Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating payments...\n",
      "Generated 150 payments\n",
      "‚úì Inserted 150 payments\n",
      "Sample payment IDs: ['3adfaa34-c4e7-4092-b0a6-162ccffc1c94', 'd1413c39-b0d2-43bc-9a8e-8af0b7944a00', 'c754d325-c540-46f8-a10a-ba57c97f60db', '051b85a1-9102-41a8-a376-2cc5dfdb60d4', 'dc8b94e4-e8e7-42fb-a104-3f0035f10ded']\n"
     ]
    }
   ],
   "source": [
    "# Manual random generation\n",
    "print(\"Generating payments...\")\n",
    "\n",
    "payments_data = []\n",
    "\n",
    "# Create one payment per order\n",
    "for order_id in order_ids:\n",
    "    # Get the order total (we calculated this in section 2.7.1)\n",
    "    # Fetch it from order_totals dict if available, otherwise query DB\n",
    "    order_total = 0.0\n",
    "    \n",
    "    # Query the order to get its total\n",
    "    order_result = db.client.table('orders').select('total').eq('order_id', order_id).execute()\n",
    "    if order_result.data:\n",
    "        order_total = float(order_result.data[0]['total'])\n",
    "    \n",
    "    # Generate payment record\n",
    "    payment_method = random.choice(['card', 'cash', 'bank_transfer', 'paypal'])\n",
    "    status = random.choice(['completed'] * 8 + ['pending'] * 1 + ['failed'] * 1)  # 80% completed\n",
    "    \n",
    "    payments_data.append({\n",
    "        'order_id': order_id,\n",
    "        'amount': order_total,\n",
    "        'payment_method': payment_method,\n",
    "        'status': status,\n",
    "        'transaction_id': f\"TXN-{random.randint(100000, 999999)}-{order_id[:8]}\"\n",
    "    })\n",
    "\n",
    "print(f\"Generated {len(payments_data)} payments\")\n",
    "\n",
    "payment_ids = db.insert_payments(payments_data)\n",
    "print(f\"‚úì Inserted {len(payment_ids)} payments\")\n",
    "print(f\"Sample payment IDs: {payment_ids[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Generate and Insert Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating reviews...\n",
      "‚úì Generated 167 validated records\n",
      "Generated 167 reviews\n",
      "‚úì Inserted 167 reviews\n",
      "Sample review IDs: ['d189fbf5-f99c-4d04-9952-751e22056aff', '294b1d1d-231f-48e0-bedf-2d22bd870f50', '20f931ef-7c3a-4d95-b785-08e9031d21dc', '97631e8b-6d86-4304-8686-e37a7aceb11d', '7b318fd3-9b72-4b12-bcbe-e2183535396b']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating reviews...\")\n",
    "reviews_data = generator.generate_reviews(DATA_COUNTS['reviews'], customer_ids, album_ids)\n",
    "print(f\"Generated {len(reviews_data)} reviews\")\n",
    "\n",
    "review_ids = db.insert_reviews(reviews_data)\n",
    "print(f\"‚úì Inserted {len(review_ids)} reviews\")\n",
    "print(f\"Sample review IDs: {review_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Generate and Insert Sales Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sales transactions...\n",
      "Generated 1601 sales transactions\n",
      "‚úì Inserted 1601 sales transactions\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating sales transactions...\")\n",
    "\n",
    "# Sales transactions are audit records based on order_items\n",
    "# We'll create sale transactions for each order item\n",
    "sales_data = []\n",
    "\n",
    "# Fetch order items to create corresponding sales transactions\n",
    "for order_item in order_items_data:\n",
    "    # Find the inventory_id for this album\n",
    "    album_id = order_item['album_id']\n",
    "    inventory_id = next((inv_id for inv_id, alb_id in zip(inventory_ids, album_ids) if alb_id == album_id), None)\n",
    "    \n",
    "    if inventory_id:\n",
    "        # Fetch album price (we'll need to query this or store it)\n",
    "        # For now, we'll create the transaction without unit_price\n",
    "        sales_data.append({\n",
    "            'inventory_id': inventory_id,\n",
    "            'order_id': order_item['order_id'],\n",
    "            'transaction_type': 'sale',\n",
    "            'quantity_change': -order_item['quantity']  # Negative for sales\n",
    "        })\n",
    "\n",
    "print(f\"Generated {len(sales_data)} sales transactions\")\n",
    "\n",
    "db.insert_sales(sales_data)\n",
    "print(f\"‚úì Inserted {len(sales_data)} sales transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11. Generate and Insert Workflows (UNUSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating workflows...\")\n",
    "workflows_data = generator.generate_workflows(DATA_COUNTS['workflows'])\n",
    "print(f\"Generated {len(workflows_data)} workflows\")\n",
    "\n",
    "# Debug: Inspect first workflow with complex JSON fields\n",
    "print(\"\\nüìã Sample generated workflow:\")\n",
    "print(json.dumps(workflows_data[0] if workflows_data else {}, indent=2))\n",
    "\n",
    "workflow_ids = db.insert_workflows(workflows_data)\n",
    "print(f\"\\n‚úì Inserted {len(workflow_ids)} workflows\")\n",
    "print(f\"Sample workflow IDs: {workflow_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12. Completion and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì LangFuse traces flushed to dashboard\n"
     ]
    }
   ],
   "source": [
    "# Flush all traces to LangFuse\n",
    "langfuse_client.flush()\n",
    "print(\"‚úì LangFuse traces flushed to dashboard\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed\n",
      "‚úì Database connection closed\n"
     ]
    }
   ],
   "source": [
    "db.close()\n",
    "print(\"‚úì Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
