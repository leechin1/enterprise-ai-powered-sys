{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Data Generation with Gemini API\n",
    "\n",
    "This notebook orchestrates data generation and insertion into the database.\n",
    "Run each cell sequentially to generate and insert data while monitoring for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables FIRST\n",
    "load_dotenv()\n",
    "\n",
    "from langfuse import observe, get_client  # traceability\n",
    "\n",
    "# Import configurations and templates\n",
    "from config import *\n",
    "from db_connector import DatabaseConnector\n",
    "\n",
    "# Prompts directory\n",
    "PROMPTS_DIR = Path(\"prompts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking configuration...\n",
      "\n",
      "âœ… GEMINI_API_KEY: AIzaSyBmeV92JOQ...\n",
      "âœ… LANGFUSE_PUBLIC_KEY: pk-lf-f2596628-...\n",
      "âœ… LANGFUSE_SECRET_KEY: sk-lf-9793468d-...\n",
      "âœ… LANGFUSE_HOST: https://cloud.l...\n",
      "\n",
      "==================================================\n",
      "ðŸŽ‰ Perfect! Ready to start tracing!\n"
     ]
    }
   ],
   "source": [
    "# Testing environment\n",
    "print(\"ðŸ” Checking configuration...\\n\")\n",
    "\n",
    "# Check each variable\n",
    "required = {\n",
    "    \"GEMINI_API_KEY\": os.getenv(\"GEMINI_API_KEY\"),\n",
    "    \"LANGFUSE_PUBLIC_KEY\": os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    \"LANGFUSE_SECRET_KEY\": os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    \"LANGFUSE_HOST\": os.getenv(\"LANGFUSE_HOST\")\n",
    "}\n",
    "\n",
    "all_set = True\n",
    "for name, value in required.items():\n",
    "    if value:\n",
    "        display = value[:15] + \"...\" if len(value) > 15 else value\n",
    "        print(f\"âœ… {name}: {display}\")\n",
    "    else:\n",
    "        print(f\"âŒ {name}: NOT SET\")\n",
    "        all_set = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all_set:\n",
    "    print(\"ðŸŽ‰ Perfect! Ready to start tracing!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Please add missing keys to your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 1: SmartJSON Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ SmartJSONExtractor class loaded\n"
     ]
    }
   ],
   "source": [
    "class SmartJSONExtractor:\n",
    "    \"\"\"Robust JSON extraction from LLM responses\"\"\"\n",
    "\n",
    "    def extract(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Extract JSON from text with multiple fallback strategies\n",
    "\n",
    "        Args:\n",
    "            text: Raw text that may contain JSON\n",
    "\n",
    "        Returns:\n",
    "            Dict with 'success' (bool), 'data' (parsed JSON), 'error' (str)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Strategy 1: Try direct parsing\n",
    "            data = json.loads(text.strip())\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 2: Remove markdown code blocks\n",
    "            cleaned = self._remove_code_blocks(text)\n",
    "            data = json.loads(cleaned)\n",
    "            return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # Strategy 3: Extract first JSON array or object found\n",
    "            json_match = re.search(r'(\\[[\\s\\S]*\\]|\\{[\\s\\S]*\\})', text)\n",
    "            if json_match:\n",
    "                data = json.loads(json_match.group(1))\n",
    "                return {\"success\": True, \"data\": data, \"error\": None}\n",
    "        except (json.JSONDecodeError, AttributeError):\n",
    "            pass\n",
    "\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"data\": None,\n",
    "            \"error\": \"Failed to extract valid JSON from response\"\n",
    "        }\n",
    "\n",
    "    def _remove_code_blocks(self, text: str) -> str:\n",
    "        \"\"\"Remove markdown code block formatting\"\"\"\n",
    "        text = text.strip()\n",
    "        if text.startswith('```'):\n",
    "            lines = text.split('\\n')\n",
    "            text = '\\n'.join(lines[1:-1]) if len(lines) > 2 else text\n",
    "            if text.startswith('json'):\n",
    "                text = text[4:].strip()\n",
    "        return text\n",
    "\n",
    "print(\"âœ“ SmartJSONExtractor class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 2: Gemini Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GeminiDataGenerator class loaded\n"
     ]
    }
   ],
   "source": [
    "class GeminiDataGenerator:\n",
    "    \"\"\"Generate realistic fake data using Gemini API with structured output\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "        self.extractor = SmartJSONExtractor()\n",
    "        self.generation_config = types.GenerateContentConfig(\n",
    "            temperature=GEMINI_TEMPERATURE,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "        )\n",
    "        self.TEMPLATES = TEMPLATES\n",
    "\n",
    "    def _load_prompt(self, prompt_file: str) -> str:\n",
    "        \"\"\"Load prompt from file\"\"\"\n",
    "        prompt_path = PROMPTS_DIR / prompt_file\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "\n",
    "    @observe()\n",
    "    def _build_structured_prompt(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        schema: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Build a structured prompt using the CRITICAL format with json.dumps schema\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            schema: Schema template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "\n",
    "        Returns:\n",
    "            Formatted prompt string\n",
    "        \"\"\"\n",
    "        # Create example schema for a single record\n",
    "        single_record_schema = schema\n",
    "        # Full schema is an array of records\n",
    "        full_schema = {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": single_record_schema,\n",
    "            \"minItems\": count,\n",
    "            \"maxItems\": count\n",
    "        }\n",
    "\n",
    "        prompt_parts = [\n",
    "            \"CRITICAL: Output ONLY valid JSON matching this exact schema.\",\n",
    "            \"No other text, no markdown, no explanations.\\n\",\n",
    "            f\"Schema:\\n{json.dumps(full_schema, indent=2)}\\n\",\n",
    "            f\"Instructions:\\n{instructions}\\n\"\n",
    "        ]\n",
    "\n",
    "        if reference_ids:\n",
    "            prompt_parts.append(\"Reference IDs (use these for foreign key fields):\")\n",
    "            for key, ids in reference_ids.items():\n",
    "                sample_ids = ids[:10] if len(ids) > 10 else ids\n",
    "                prompt_parts.append(f\"- {key}: {sample_ids}\")\n",
    "            prompt_parts.append(\"\")\n",
    "\n",
    "        prompt_parts.append(f\"Generate exactly {count} records.\\n\")\n",
    "        prompt_parts.append(\"JSON:\")\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    @observe()\n",
    "    def extract_structured_form(\n",
    "        self,\n",
    "        instructions: str,\n",
    "        form_template: Dict[str, Any],\n",
    "        count: int,\n",
    "        reference_ids: Optional[Dict[str, List[str]]] = None,\n",
    "        model_class: Optional[BaseModel] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Extract data matching a form template with validation\n",
    "\n",
    "        Args:\n",
    "            instructions: Natural language instructions for data generation\n",
    "            form_template: Template defining the expected structure\n",
    "            count: Number of records to generate\n",
    "            reference_ids: Optional dict of reference IDs for foreign keys\n",
    "            model_class: Optional Pydantic model for validation\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        # Build structured prompt using new format\n",
    "        full_prompt = self._build_structured_prompt(\n",
    "            instructions,\n",
    "            form_template,\n",
    "            count,\n",
    "            reference_ids\n",
    "        )\n",
    "\n",
    "        # Generate with retry\n",
    "        return self._generate_with_validation(full_prompt, count, model_class)\n",
    "\n",
    "    @observe()\n",
    "    def _generate_with_validation(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        expected_count: int,\n",
    "        model_class: Optional[BaseModel] = None,\n",
    "        retry: int = 0\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate content with retry and optional Pydantic validation\n",
    "\n",
    "        Args:\n",
    "            prompt: Full prompt to send\n",
    "            expected_count: Expected number of records\n",
    "            model_class: Optional Pydantic model for validation\n",
    "            retry: Current retry attempt\n",
    "\n",
    "        Returns:\n",
    "            List of validated dictionaries\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=GEMINI_MODEL,\n",
    "                contents=prompt,\n",
    "                config=self.generation_config\n",
    "            )\n",
    "\n",
    "            # Extract JSON\n",
    "            result = self.extractor.extract(response.text)\n",
    "\n",
    "            if not result[\"success\"]:\n",
    "                raise ValueError(result[\"error\"])\n",
    "\n",
    "            data = result[\"data\"]\n",
    "\n",
    "            # Validate with Pydantic \n",
    "            if model_class:\n",
    "                validated_data = []\n",
    "                for i, item in enumerate(data):\n",
    "                    try:\n",
    "                        validated_item = model_class(**item)\n",
    "                        validated_data.append(validated_item.model_dump())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Validation warning for record {i+1}: {e}\")\n",
    "                        validated_data.append(item)  \n",
    "                data = validated_data\n",
    "\n",
    "            actual_count = len(data)\n",
    "            print(f\"âœ“ Generated {actual_count} validated records\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            if retry < GEMINI_MAX_RETRIES:\n",
    "                print(f\"Error (attempt {retry + 1}/{GEMINI_MAX_RETRIES}): {e}\")\n",
    "                time.sleep(2 ** retry)  # Exponential backoff\n",
    "                return self._generate_with_validation(prompt, expected_count, model_class, retry + 1)\n",
    "            else:\n",
    "                print(f\" Failed after {GEMINI_MAX_RETRIES} attempts: {e}\")\n",
    "                return []\n",
    "\n",
    "# ENTITY TYPE SPECIFIC COMPILING ----------------------------\n",
    "    @observe()\n",
    "    def generate_genres(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate music genres\"\"\"\n",
    "        instructions = self._load_prompt('genre_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['genre'],\n",
    "            count,\n",
    "            model_class=Genre\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_labels(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate record labels\"\"\"\n",
    "        instructions = self._load_prompt('label_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['label'],\n",
    "            count,\n",
    "            model_class=Label\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_customers(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate customers\"\"\"\n",
    "        instructions = self._load_prompt('customer_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['customer'],\n",
    "            count,\n",
    "            model_class=Customer\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_albums(self, count: int, genre_ids: List[str], label_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate albums with references to genres and labels\"\"\"\n",
    "        instructions = self._load_prompt('album_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['album'],\n",
    "            count,\n",
    "            reference_ids={'genre_ids': genre_ids, 'label_ids': label_ids},\n",
    "            model_class=Album\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_orders(self, count: int, customer_ids: List[str]) -> List[Dict]:\n",
    "        \"\"\"Generate orders\"\"\"\n",
    "        instructions = self._load_prompt('order_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['order'],\n",
    "            count,\n",
    "            reference_ids={'customer_ids': customer_ids},\n",
    "            model_class=Order\n",
    "        )\n",
    "\n",
    "    @observe()\n",
    "    def generate_workflows(self, count: int) -> List[Dict]:\n",
    "        \"\"\"Generate workflow definitions\"\"\"\n",
    "        instructions = self._load_prompt('workflow_prompt.txt')\n",
    "        return self.extract_structured_form(\n",
    "            instructions,\n",
    "            self.TEMPLATES['workflow'],\n",
    "            count,\n",
    "            model_class=Workflow\n",
    "        )\n",
    "\n",
    "print(\"âœ“ GeminiDataGenerator class loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Available prompt files:\n",
      "  - album_prompt.txt\n",
      "  - customer_prompt.txt\n",
      "  - genre_prompt.txt\n",
      "  - label_prompt.txt\n",
      "  - order_prompt.txt\n",
      "  - workflow_prompt.txt\n",
      "\n",
      "============================================================\n",
      "JSON TEMPLATES (Schemas)\n",
      "============================================================\n",
      "\n",
      "GENRE:\n",
      "{\n",
      "  \"name\": null\n",
      "}\n",
      "\n",
      "LABEL:\n",
      "{\n",
      "  \"name\": null\n",
      "}\n",
      "\n",
      "CUSTOMER:\n",
      "{\n",
      "  \"email\": null,\n",
      "  \"first_name\": null,\n",
      "  \"last_name\": null,\n",
      "  \"phone\": null\n",
      "}\n",
      "\n",
      "ALBUM:\n",
      "{\n",
      "  \"title\": null,\n",
      "  \"artist\": null,\n",
      "  \"genre_id\": null,\n",
      "  \"label_id\": null,\n",
      "  \"price\": null\n",
      "}\n",
      "\n",
      "ORDER:\n",
      "{\n",
      "  \"order_number\": null,\n",
      "  \"customer_id\": null,\n",
      "  \"total\": null,\n",
      "  \"shipping_address\": null,\n",
      "  \"order_date\": null\n",
      "}\n",
      "\n",
      "WORKFLOW:\n",
      "{\n",
      "  \"name\": null,\n",
      "  \"description\": null,\n",
      "  \"trigger_type\": null,\n",
      "  \"trigger_config\": {},\n",
      "  \"workflow_definition\": {},\n",
      "  \"enabled\": null\n",
      "}\n",
      "\n",
      "============================================================\n",
      "âœ“ Prompt/template inspection utilities loaded\n"
     ]
    }
   ],
   "source": [
    "def list_prompts():\n",
    "    \"\"\"List all available prompt files\"\"\"\n",
    "    prompts_dir = Path(\"prompts\")\n",
    "    if prompts_dir.exists():\n",
    "        print(\"ðŸ“„ Available prompt files:\")\n",
    "        for prompt_file in sorted(prompts_dir.glob(\"*.txt\")):\n",
    "            print(f\"  - {prompt_file.name}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Prompts directory not found\")\n",
    "\n",
    "def show_prompt(prompt_name: str):\n",
    "    \"\"\"Display content of a specific prompt file\"\"\"\n",
    "    prompt_path = Path(\"prompts\") / prompt_name\n",
    "    if prompt_path.exists():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PROMPT: {prompt_name}\")\n",
    "        print('='*60)\n",
    "        with open(prompt_path, 'r') as f:\n",
    "            print(f.read())\n",
    "        print('='*60 + '\\n')\n",
    "    else:\n",
    "        print(f\" Prompt file not found: {prompt_name}\")\n",
    "\n",
    "def show_all_templates():\n",
    "    \"\"\"Display all JSON templates\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"JSON TEMPLATES (Schemas)\")\n",
    "    print(\"=\"*60)\n",
    "    for name, template in TEMPLATES.items():\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        print(json.dumps(template, indent=2))\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Uncomment to view:\n",
    "list_prompts()\n",
    "show_all_templates()\n",
    "\n",
    "print(\"âœ“ Prompt/template inspection utilities loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize Generator and Database Connection + Traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Generator, DB connector and langfuse initialized\n"
     ]
    }
   ],
   "source": [
    "generator = GeminiDataGenerator()\n",
    "db = DatabaseConnector()\n",
    "\n",
    "# Initialize LangFuse client\n",
    "langfuse_client = get_client()\n",
    "\n",
    "\n",
    "print(\"âœ“ Generator, DB connector and langfuse initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Inspect Prompt and Schema (Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Debugging utilities loaded. Uncomment lines above to inspect prompts.\n"
     ]
    }
   ],
   "source": [
    "# Optional: Inspect how prompts are structured\n",
    "# This cell shows you the exact prompt and schema sent to Gemini API\n",
    "\n",
    "def inspect_prompt_for_entity(entity_name: str, template_key: str, count: int = 5):\n",
    "    \"\"\"Show the structured prompt for any entity\"\"\"\n",
    "    generator_temp = GeminiDataGenerator()\n",
    "    \n",
    "    # Load the prompt\n",
    "    prompt_text = generator_temp._load_prompt(f'{entity_name}_prompt.txt')\n",
    "    \n",
    "    # Get the schema\n",
    "    schema = TEMPLATES[template_key]\n",
    "    \n",
    "    # Build the prompt using the same method\n",
    "    full_prompt = generator_temp._build_structured_prompt(\n",
    "        prompt_text,\n",
    "        schema,\n",
    "        count\n",
    "    )\n",
    "    \n",
    "    print(f\"=== PROMPT FOR {entity_name.upper()} ===\\n\")\n",
    "    print(full_prompt)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Example: Inspect genre prompt (comment/uncomment to test different entities)\n",
    "# inspect_prompt_for_entity('genre', 'genre', 5)\n",
    "# inspect_prompt_for_entity('album', 'album', 3)\n",
    "\n",
    "print(\"âœ“ Debugging utilities loaded. Uncomment lines above to inspect prompts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Error Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Error tracking initialized\n"
     ]
    }
   ],
   "source": [
    "# Track errors and warnings throughout the process\n",
    "error_log = []\n",
    "warning_log = []\n",
    "\n",
    "def log_error(step: str, error: Exception):\n",
    "    \"\"\"Log an error for later review\"\"\"\n",
    "    error_log.append({\"step\": step, \"error\": str(error), \"type\": type(error).__name__})\n",
    "    print(f\" ERROR in {step}: {error}\")\n",
    "\n",
    "def log_warning(step: str, message: str):\n",
    "    \"\"\"Log a warning for later review\"\"\"\n",
    "    warning_log.append({\"step\": step, \"message\": message})\n",
    "    print(f\"âš ï¸  WARNING in {step}: {message}\")\n",
    "\n",
    "def show_logs():\n",
    "    \"\"\"Display all errors and warnings\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERROR AND WARNING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if error_log:\n",
    "        print(f\"\\n ERRORS ({len(error_log)}):\")\n",
    "        for i, err in enumerate(error_log, 1):\n",
    "            print(f\"\\n{i}. {err['step']} ({err['type']})\")\n",
    "            print(f\"   {err['error']}\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ No errors!\")\n",
    "    \n",
    "    if warning_log:\n",
    "        print(f\"\\nâš ï¸  WARNINGS ({len(warning_log)}):\")\n",
    "        for i, warn in enumerate(warning_log, 1):\n",
    "            print(f\"\\n{i}. {warn['step']}\")\n",
    "            print(f\"   {warn['message']}\")\n",
    "    else:\n",
    "        print(\"\\nâœ“ No warnings!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"âœ“ Error tracking initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Supabase successfully\n",
      "âœ“ Connected to database\n"
     ]
    }
   ],
   "source": [
    "db.connect()\n",
    "print(\"âœ“ Connected to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Generate and Insert Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating genres...\n",
      "âœ“ Generated 15 validated records\n",
      "Generated 15 genres\n",
      "âœ“ Inserted 15 genres\n",
      "Sample genre IDs: ['64ad1b22-c173-4b15-9f64-636bdb9e5942', 'ca555ee1-89fd-4fe7-b787-5803d8ae8dea', '241cc333-0347-4d69-a3d1-8f53d78c1bf1', 'cb9e1bdd-ccda-4793-813e-6b1043d1fc60', 'b0ccf25c-9aea-46a6-86df-a506f802c37b']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating genres...\")\n",
    "genres_data = generator.generate_genres(DATA_COUNTS['genres'])\n",
    "print(f\"Generated {len(genres_data)} genres\")\n",
    "\n",
    "genre_ids = db.insert_genres(genres_data)\n",
    "print(f\"âœ“ Inserted {len(genre_ids)} genres\")\n",
    "print(f\"Sample genre IDs: {genre_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Generate and Insert Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels...\n",
      "Error (attempt 1/3): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 21.90560146s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}\n",
      "Error (attempt 2/3): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 20.081481381s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error (attempt 3/3): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 17.195777853s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}\n",
      " Failed after 3 attempts: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 12.334136125s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}\n",
      "Generated 0 labels\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "{'message': '\"failed to parse columns parameter ()\" (line 1, column 1)', 'code': 'PGRST100', 'hint': None, 'details': 'unexpected end of input expecting field name (* or [a..z0..9_$])'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m labels_data = generator.generate_labels(DATA_COUNTS[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m label_ids = \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Inserted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(label_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample label IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_ids[:\u001b[32m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/enterprise-ai-powered-sys/data-gen/db_connector.py:49\u001b[39m, in \u001b[36mDatabaseConnector.insert_labels\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minsert_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: List[Dict]) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Insert labels and return UUIDs\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [row[\u001b[33m'\u001b[39m\u001b[33mlabel_id\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m result.data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/enterprise-ai-powered-sys/.venv/lib/python3.13/site-packages/postgrest/_sync/request_builder.py:53\u001b[39m, in \u001b[36mSyncQueryRequestBuilder.execute\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         json_obj = model_validate_json(APIErrorFromJSON, r.content)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m APIError(\u001b[38;5;28mdict\u001b[39m(json_obj))\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(generate_default_error_message(r))\n",
      "\u001b[31mAPIError\u001b[39m: {'message': '\"failed to parse columns parameter ()\" (line 1, column 1)', 'code': 'PGRST100', 'hint': None, 'details': 'unexpected end of input expecting field name (* or [a..z0..9_$])'}"
     ]
    }
   ],
   "source": [
    "print(\"Generating labels...\")\n",
    "labels_data = generator.generate_labels(DATA_COUNTS['labels'])\n",
    "print(f\"Generated {len(labels_data)} labels\")\n",
    "\n",
    "label_ids = db.insert_labels(labels_data)\n",
    "print(f\"âœ“ Inserted {len(label_ids)} labels\")\n",
    "print(f\"Sample label IDs: {label_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Generate and Insert Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating customers...\")\n",
    "customers_data = generator.generate_customers(DATA_COUNTS['customers'])\n",
    "print(f\"Generated {len(customers_data)} customers\")\n",
    "\n",
    "customer_ids = db.insert_customers(customers_data)\n",
    "print(f\"âœ“ Inserted {len(customer_ids)} customers\")\n",
    "print(f\"Sample customer IDs: {customer_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Generate and Insert Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating albums...\")\n",
    "albums_data = generator.generate_albums(DATA_COUNTS['albums'], genre_ids, label_ids)\n",
    "print(f\"Generated {len(albums_data)} albums\")\n",
    "\n",
    "album_ids = db.insert_albums(albums_data)\n",
    "print(f\"âœ“ Inserted {len(album_ids)} albums\")\n",
    "print(f\"Sample album IDs: {album_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generate and Insert Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating inventory...\")\n",
    "# Simple inventory: each album gets basic stock\n",
    "inventory_ids = album_ids  # Reuse album IDs for simplicity\n",
    "print(f\"âœ“ Using {len(inventory_ids)} inventory records (one per album)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Generate and Insert Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating orders...\")\n",
    "orders_data = generator.generate_orders(DATA_COUNTS['orders'], customer_ids)\n",
    "print(f\"Generated {len(orders_data)} orders\")\n",
    "\n",
    "order_ids = db.insert_orders(orders_data)\n",
    "print(f\"âœ“ Inserted {len(order_ids)} orders\")\n",
    "print(f\"Sample order IDs: {order_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Generate and Insert Order Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating order items...\")\n",
    "# Each order references albums - dependencies handled by database foreign keys\n",
    "print(\"âœ“ Order items handled through order-album relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Generate and Insert Payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating payments...\")\n",
    "# Payments linked to orders via foreign keys in database\n",
    "print(\"âœ“ Payment records linked to orders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Generate and Insert Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating reviews...\")\n",
    "# Reviews link customers to albums\n",
    "print(\"âœ“ Review relationships handled by customer-album foreign keys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Generate and Insert Sales Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating workflows...\")\n",
    "workflows_data = generator.generate_workflows(DATA_COUNTS['workflows'])\n",
    "print(f\"Generated {len(workflows_data)} workflows\")\n",
    "\n",
    "# Debug: Inspect first workflow with complex JSON fields\n",
    "print(\"\\nðŸ“‹ Sample generated workflow:\")\n",
    "print(json.dumps(workflows_data[0] if workflows_data else {}, indent=2))\n",
    "\n",
    "workflow_ids = db.insert_workflows(workflows_data)\n",
    "print(f\"\\nâœ“ Inserted {len(workflow_ids)} workflows\")\n",
    "print(f\"Sample workflow IDs: {workflow_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11. Generate and Insert Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"âœ“ DATA GENERATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show error and warning summary\n",
    "show_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12. Generate and Insert Workflow Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating workflow executions...\")\n",
    "# Workflow executions reference workflow IDs\n",
    "print(\"âœ“ Workflow execution records linked to workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13. Completion and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"âœ“ DATA GENERATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flush all traces to LangFuse\n",
    "langfuse_client.flush()\n",
    "print(\"âœ“ LangFuse traces flushed to dashboard\")\n",
    "print(\"   Check your LangFuse dashboard: https://cloud.langfuse.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flush LangFuse Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close Database Connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()\n",
    "print(\"âœ“ Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
